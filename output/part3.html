<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
<head>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-51676383-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-51676383-1');
</script>

<title>Part 3: Building a Simple Neural Network</title>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
       equationNumbers: { autoNumber: "AMS" },
       TagSide: "right"

    }
  });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<link rel="stylesheet" href="pygments.css">
<link rel="stylesheet" href="style.css">
<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
</head>

<body>

<div id="outer">
    <div id="inner">
<center><h1>Part 3: Building a Simple Neural Network <span style="color: red">[Draft]</span></h1></center>
<center><b>Sait Celebi</b> (celebisait@gmail.com)</center>
<center>Last updated: February 19 2018</center><p>
"Truth is ever to be found in the simplicity, and not in the multiplicity and confusion of things."
-- Sir Isaac Newton
</p>

<h1>Introduction</h1>
<p>
Let's say we want to build a model to discriminate the following <b>red</b> and <b>green</b>
points in 2-dimensional space:
</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">collections</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.214</span><span class="p">,</span> <span class="mf">0.052</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.15</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.282</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.464</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.282</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.214</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">,</span>
                <span class="o">-</span><span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.052</span><span class="p">,</span> <span class="mf">0.23</span><span class="p">,</span> <span class="mf">1.214</span><span class="p">,</span><span class="o">-</span><span class="mf">0.464</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.214</span><span class="p">,</span>  <span class="mf">0.464</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span> <span class="mf">0.23</span><span class="p">,</span> <span class="mf">0.464</span><span class="p">],</span>
	      <span class="p">[</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.882</span><span class="p">,</span> <span class="mf">0.295</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.26</span><span class="p">,</span> <span class="mf">0.103</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.427</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.103</span><span class="p">,</span> <span class="mf">0.882</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
	        <span class="o">-</span><span class="mf">0.26</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.295</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.193</span><span class="p">,</span> <span class="mf">0.882</span><span class="p">,</span> <span class="mf">1.427</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.882</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.427</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.193</span><span class="p">,</span> <span class="mf">1.427</span><span class="p">]])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">0.65</span><span class="p">,</span>  <span class="o">-</span><span class="mf">0.</span><span class="p">,</span>    <span class="o">-</span><span class="mf">0.75</span><span class="p">,</span>   <span class="mf">1.299</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.46</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.299</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.</span><span class="p">,</span>     <span class="mf">0.46</span><span class="p">,</span>   <span class="mf">0.46</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.299</span><span class="p">,</span>
  <span class="o">-</span><span class="mf">0.46</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">,</span>     <span class="mf">0.75</span><span class="p">,</span>   <span class="mf">1.299</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.65</span><span class="p">,</span>   <span class="mf">1.5</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.5</span><span class="p">,</span>    <span class="mf">0.75</span><span class="p">,</span>  <span class="o">-</span><span class="mf">0.75</span><span class="p">,</span>   <span class="mf">0.</span>   <span class="p">],</span>
 <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>    <span class="o">-</span><span class="mf">0.65</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.299</span><span class="p">,</span>  <span class="mf">0.75</span><span class="p">,</span>  <span class="o">-</span><span class="mf">0.46</span><span class="p">,</span>  <span class="o">-</span><span class="mf">0.75</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.5</span><span class="p">,</span>  <span class="mf">0.46</span><span class="p">,</span>  <span class="o">-</span><span class="mf">0.46</span><span class="p">,</span>   <span class="mf">0.75</span><span class="p">,</span>
   <span class="mf">0.46</span><span class="p">,</span>  <span class="mf">0.65</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.299</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.75</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.299</span><span class="p">,</span>  <span class="mf">1.299</span><span class="p">,</span>  <span class="mf">1.5</span>  <span class="p">]])</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="n">colormap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">plot_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">colormap</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$x_2$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Input 2D points&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colormap</span><span class="p">[</span><span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="n">plot_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">colormap</span><span class="p">,</span> <span class="s1">&#39;image.png&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
</pre></div>
<img class="generated_image" width="600" src="../images/image000.png"/><p>
In other words, given a point, $(x_1, x_2)$, we want to output either <b>red</b>,
or <b>green</b>. (In this tutorial 0.0 means red and 1.0 means green.)
</p>

<p>
We can build a simple Neural Network for this problem. Neural Networks are widely used
for applications ranging from face recognition, machine translation, speech to text,
self driving cars, etc.  This is a very simple neural network in terms of number of layers and
number of neurons it contains.
</p>

<h1>Computation Graph</h1>

<p>
Here is a visual representation of our model:
</p>

<img class="static_image" style="width: 800px;" src="../static_images/image006.png"/>

<p>
and decide if $A^{(3)} > 0.5$ four our <b>final prediction</b>.
</p>

<h1>Feed-forward Phase</h1>

<p>
Let's assume that we are given the weights and biases. How do we calculate the output?
</p>

<p>
We represent $X$ as a matrix. $X$ contains all the points. In our case $X$ contains $M=20$
samples and for each sample we have $(x,y)$. $Y$ contains all the labels (red or green):
</p>

$$
X =
\begin{bmatrix}
0   &  0   & \dots &  0 \\
0   &  0   & \dots &  0 \\
\end{bmatrix}_{2 \times M}, \quad
Y =
\begin{bmatrix}
0   &  0   & \dots &  0 \\
\end{bmatrix}_{1 \times M}, \quad
$$

<p>
Here is the <b>parameters</b> of our model:
</p>

$$
W^{(1)} =
\begin{bmatrix}
0   &  0   \\
0   &  0   \\
0   &  0   \\
\end{bmatrix}_{3 \times 2}, \quad
b^{(1)} =
\begin{bmatrix}
0  \\
0  \\
0  \\
\end{bmatrix}_{3 \times 1}
$$

$$
W^{(2)} =
\begin{bmatrix}
0   &  0  &   0  \\
0   &  0  &   0  \\
0   &  0  &   0  \\
\end{bmatrix}_{3 \times 3}, \quad
b^{(2)} =
\begin{bmatrix}
0  \\
0  \\
0  \\
\end{bmatrix}_{3 \times 1}
$$

$$
W^{(3)} =
\begin{bmatrix}
0  &  0  &   0   \\
\end{bmatrix}_{1 \times 3}, \quad
b^{(3)} =
\begin{bmatrix}
0  \\
\end{bmatrix}_{1 \times 1}
$$

<p>
Feed-forward basically means given $X, Y, W^{(1)}, W^{(2)}, W^{(3)}$ and $b^{(1)}, b^{(2)}, b^{(3)}$
will produce us $A^{(3)}$. Here is step by step how we do the feed forward phase.
</p>

$$
Z^{(1)} = W^{(1)} X + b^{(1)}
$$

$$
A^{(1)} = g(Z^{(1)})
$$

$$
Z^{(2)} = W^{(2)} A^{(1)} + b^{(2)}
$$

$$
A^{(2)} = g(Z^{(2)})
$$

$$
Z^{(3)} = W^{(3)} A^{(2)} + b^{(3)}
$$

$$
A^{(3)} = g(Z^{(3)})
$$

<p>
We are using sigmoid function as the activation $g()$ function as we used before.
</p>

<p>
Let's try to apply this using an <b>initial</b> random set of weights and bias.
</p>
<div class="highlight"><pre><span></span><span class="n">sigmoid</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">forward_propagate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">):</span>
  <span class="n">Z1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>
  <span class="n">A1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>

  <span class="n">Z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">A1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
  <span class="n">A2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span>

  <span class="n">Z3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W3</span><span class="p">,</span> <span class="n">A2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b3</span>
  <span class="n">A3</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z3</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">Z1</span><span class="p">,</span> <span class="n">A1</span><span class="p">,</span> <span class="n">Z2</span><span class="p">,</span> <span class="n">A2</span><span class="p">,</span> <span class="n">Z3</span><span class="p">,</span> <span class="n">A3</span>

<span class="n">W1_initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">W1_initial</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">W2_initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">W2_initial</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">W3_initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">W3</span> <span class="o">=</span> <span class="n">W3_initial</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">b3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">Z1</span><span class="p">,</span> <span class="n">A1</span><span class="p">,</span> <span class="n">Z2</span><span class="p">,</span> <span class="n">A2</span><span class="p">,</span> <span class="n">Z3</span><span class="p">,</span> <span class="n">A3</span> <span class="o">=</span> <span class="n">forward_propagate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">A3</span><span class="p">)</span>
</pre></div>
<div class="code_stdout"><pre>[[0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1]]
[[ 0.649  0.639  0.629  0.658  0.638  0.631  0.631  0.652  0.644  0.646
   0.648  0.652  0.637  0.646  0.642  0.654  0.637  0.66   0.654  0.658]]
</pre></div><p>
Above we print the predictions for a random initial set of weights and bias. We are <b>randomly
initializing</b> weights and bias and feeding $X$ to our random initial model. As you can see,
our predictions are pretty random too, as expected. However, you can see that, given the weights,
and bias, it is pretty straight-forward to calculate the final predictions.
The tricky part is to <i>learn</i> those weights properly.
</p>

<h1> Cross Entropy Loss Function </h1>

<p>
In training, our goal is to <b>learn</b>: $W^{(1)}, W^{(2)}, W^{(3)}, b^{(1)}, b^{(2)}, b^{(3)}$ that best <b>discriminates</b>
red and green points. These are called the <b>parameters</b> of our model.
</p>

<p>
We want to find parameters that minimizes some definition of a <b>cost function</b>. We will use the same
cost function we have derived before:
</p>

$$L = - \sum_{i=1}^{M} Y_{i} log( A^{(3)}_{i} ) + (1-Y_{i}) log( 1 - A^{(3)}_{i}  )$$

<p>
Please see previous lectures if you are interested understanding how we derived the cross entropy loss function.
</p>

<p>
If we add our <b>Log Loss</b> to our computation graph:
</p>

<img class="static_image" style="width: 800px;" src="../static_images/image007.png"/>

<h1>Backpropagation</h1>

<p>
We need Backpropagation to calculate derivatives so that we can use <b>Gradient Descent</b>.
In order to do gradient descent, we need to calculate the the derivate of loss w.r.t.
each parameter in our model. i.e.,
</p>

$$
\frac{dL}{dW^{(i)}}, \quad \frac{dL}{db^{(i)}}
$$

<p>
We will need to use <b>chain rule</b> to get there. The direction we apply chain rule will be
the opposite direction to the feed forward case.
</p>

<img class="static_image" style="width: 800px;" src="../static_images/image008.png"/>

<p>
We remember that:
</p>

$$
\frac{dL}{dZ^{(3)}} = A^{(3)} - Y
$$

<p>
from the previous lectures.
</p>

<p>
Let's try to go one step further and calculate $\frac{dL}{dW^{(3)}}$ by keeping in mind that
we already know $\frac{dL}{dZ^{(3)}}$.
</p>

<p>
In other words, we know how much $L$ changes if we play
with $Z^{(3)}$ and we are trying to find out how much $L$ changes if we play with $W^{(3)}$.
</p>

<p>
Let's look at how we calculate $Z^{(3)}$:
</p>

$$
\begin{matrix}
(W) \\
\begin{bmatrix} 0 & 0 & 0 \end{bmatrix}
\\
\\
\mbox{}
\end{matrix}

\begin{matrix}
(A) \\
\begin{bmatrix}
0  \\
0  \\
0  \\
\end{bmatrix}
\end{matrix}

+

\begin{matrix}
(b)
\\
\begin{bmatrix}
0
\end{bmatrix}
\\
\\
\end{matrix}

=

\begin{matrix}
(Z)
\\
\begin{bmatrix}
0
\end{bmatrix}
\\
\\
\end{matrix}
$$

<p>
Let's look this equation very carefully. Our question is, again: "How much $Z$ will be affected if we
play with $W$?", i.e.,
</p>

$$
\frac{dZ}{dW}
$$

<p>
It seems obvious <b>visually</b> that if we change, say, $W_1$, $Z$ will change proportional to $A_1$. Notice that
we are assuming that $A$ and $b$ is fixed and frozen. Using similar logic for the other items of $W$,
we can conclude:
</p>

$$
\frac{dZ}{dW} = A
$$

<p>
Similarly, if we change $b$ a small amount, $Z$ will also change as same amount in the same direction, so:
</p>

$$
\frac{dZ}{db} = 1
$$

<p>
To calculate $\frac{dL}{dW}$, using <b>matrix operations</b>:
</p>

$$
\begin{matrix}
(A)\\
\begin{bmatrix}
0   &  0  & ... &  0  \\
0   &  0  & ... &  0  \\
0   &  0  & ... &  0  \\
\end{bmatrix}_{3 \times 20}
\end{matrix}

\stackrel{\text{broadcasting}}{\circ}

\begin{matrix}
(\frac{dL}{dZ})\\
\begin{bmatrix}
0   &  0  & ... &  0  \\
\end{bmatrix}_{1 \times 20}
\end{matrix}

=

\begin{bmatrix}
0   &  0  & ... &  0  \\
0   &  0  & ... &  0  \\
0   &  0  & ... &  0  \\
\end{bmatrix}_{3 \times 20}

\stackrel{\text{average}}{\rightarrow}

\begin{bmatrix}
0  \\
0  \\
0  \\
\end{bmatrix}_{3 \times 1}

\stackrel{\text{transpose}}{\rightarrow}

\begin{matrix}
(\frac{dL}{dW}) \\
\begin{bmatrix}
0 & 0 & 0 \\
\end{bmatrix}_{1 \times 3}
\end{matrix}
$$

or in summary, and high-level view:

$$
\frac{dL}{dZ} \frac{dZ}{dW} = \frac{dL}{dW}
$$

and similarly for $\frac{dL}{db}$:

$$
\begin{matrix}
(\frac{dL}{dZ}) \\
\begin{bmatrix}
0   &  0  & ... &  0  \\
\end{bmatrix}_{1 \times 20}
\end{matrix}

\stackrel{\text{average}}{\rightarrow}

\begin{matrix}
(\frac{dL}{db}) \\
\begin{bmatrix}
0  \\
\end{bmatrix}_{1 \times 1}
\end{matrix}
$$

<p>
Let's apply the <b>backprop</b> altogether!
</p>
<div class="highlight"><pre><span></span><span class="n">ALPHA</span> <span class="o">=</span> <span class="mf">0.3</span>  <span class="c1"># learning rate</span>

<span class="c1"># this simple implementation is numerically unstable, because:</span>
<span class="c1"># np.log() returns -inf for small inputs very close to 0</span>
<span class="k">def</span> <span class="nf">get_loss</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Y_hat</span><span class="p">):</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">)</span> <span class="o">+</span>
                     <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">Y_hat</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">loss</span>

<span class="c1"># semantically same with above function, and numerically stable.</span>
<span class="k">def</span> <span class="nf">get_loss_numerically_stable</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Z3</span><span class="p">):</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">Z3</span><span class="p">))</span> <span class="o">+</span>
                     <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">Z3</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">Z3</span><span class="p">))))</span>
  <span class="k">return</span> <span class="n">loss</span>

<span class="k">def</span> <span class="nf">get_gradients</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="n">A1</span><span class="p">,</span> <span class="n">Z2</span><span class="p">,</span> <span class="n">A2</span><span class="p">,</span> <span class="n">Z3</span><span class="p">,</span> <span class="n">A3</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
  <span class="n">dZ3</span> <span class="o">=</span> <span class="n">A3</span> <span class="o">-</span> <span class="n">Y</span>  <span class="c1"># size (1x20)</span>

  <span class="n">dW3</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ3</span> <span class="o">*</span> <span class="n">A2</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># size (1x3)</span>
  <span class="n">db3</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ3</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># size (1x1)</span>

  <span class="n">dA2</span> <span class="o">=</span> <span class="n">W3</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">dZ3</span>  <span class="c1"># size (3x20)</span>
  <span class="n">dZ2</span> <span class="o">=</span> <span class="n">dA2</span> <span class="o">*</span> <span class="p">(</span><span class="n">A2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">A2</span><span class="p">))</span> <span class="c1"># size (3x20)</span>

  <span class="n">dW2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">dZ2</span><span class="p">,</span> <span class="n">A1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>  <span class="c1"># size (3x3)</span>
  <span class="n">db2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ2</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span> <span class="bp">True</span><span class="p">)</span>  <span class="c1"># size (3x1)</span>

  <span class="n">dA1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dZ2</span><span class="p">)</span>  <span class="c1"># size (3x20)</span>
  <span class="n">dZ1</span> <span class="o">=</span> <span class="n">dA1</span> <span class="o">*</span> <span class="p">(</span><span class="n">A1</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">A1</span><span class="p">))</span>  <span class="c1"># size (3x20)</span>

  <span class="n">dW1</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">dZ1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>  <span class="c1"># size (3x2)</span>
  <span class="n">db1</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ1</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> <span class="c1"># size (3x1)</span>

  <span class="k">return</span> <span class="n">dW1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dW2</span><span class="p">,</span> <span class="n">db2</span><span class="p">,</span> <span class="n">dW3</span><span class="p">,</span> <span class="n">db3</span>

<span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">dW1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dW2</span><span class="p">,</span> <span class="n">db2</span><span class="p">,</span> <span class="n">dW3</span><span class="p">,</span> <span class="n">db3</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
  <span class="n">W1</span> <span class="o">=</span> <span class="n">W1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">dW1</span>
  <span class="n">b1</span> <span class="o">=</span> <span class="n">b1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">db1</span>
  <span class="n">W2</span> <span class="o">=</span> <span class="n">W2</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">dW2</span>
  <span class="n">b2</span> <span class="o">=</span> <span class="n">b2</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">db2</span>
  <span class="n">W3</span> <span class="o">=</span> <span class="n">W3</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">dW3</span>
  <span class="n">b3</span> <span class="o">=</span> <span class="n">b3</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">db3</span>

  <span class="k">return</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span>

<span class="n">L_cache</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">Model</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;W1&#39;</span><span class="p">,</span> <span class="s1">&#39;b1&#39;</span><span class="p">,</span> <span class="s1">&#39;W2&#39;</span><span class="p">,</span> <span class="s1">&#39;b2&#39;</span><span class="p">,</span> <span class="s1">&#39;W3&#39;</span><span class="p">,</span> <span class="s1">&#39;b3&#39;</span><span class="p">])</span>
<span class="n">models_cache</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
  <span class="n">Z1</span><span class="p">,</span> <span class="n">A1</span><span class="p">,</span> <span class="n">Z2</span><span class="p">,</span> <span class="n">A2</span><span class="p">,</span> <span class="n">Z3</span><span class="p">,</span> <span class="n">A3</span> <span class="o">=</span> <span class="n">forward_propagate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>

  <span class="n">L</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="n">get_loss_numerically_stable</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Z3</span><span class="p">)</span>

  <span class="n">dW1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dW2</span><span class="p">,</span> <span class="n">db2</span><span class="p">,</span> <span class="n">dW3</span><span class="p">,</span> <span class="n">db3</span> <span class="o">=</span> <span class="n">get_gradients</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="n">A1</span><span class="p">,</span> <span class="n">Z2</span><span class="p">,</span> <span class="n">A2</span><span class="p">,</span> <span class="n">Z3</span><span class="p">,</span> <span class="n">A3</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

  <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">dW1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dW2</span><span class="p">,</span> <span class="n">db2</span><span class="p">,</span> <span class="n">dW3</span><span class="p">,</span> <span class="n">db3</span><span class="p">,</span> <span class="n">ALPHA</span><span class="p">)</span>
  <span class="n">m</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>

  <span class="n">models_cache</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
  <span class="n">L_cache</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">L</span> <span class="o">&lt;</span> <span class="mf">0.02</span><span class="p">:</span>
    <span class="k">break</span>

<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of iterations&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">L_cache</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;image.png&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
</pre></div>
<img class="generated_image" width="600" src="../images/image001.png"/><p>
Let's see our <b>inferences</b> on the same points using our classifier.
We are doing pretty good on inference (100%).
</p>
<div class="highlight"><pre><span></span><span class="n">Z1</span><span class="p">,</span> <span class="n">A1</span><span class="p">,</span> <span class="n">Z2</span><span class="p">,</span> <span class="n">A2</span><span class="p">,</span> <span class="n">Z3</span><span class="p">,</span> <span class="n">A3</span> <span class="o">=</span> <span class="n">forward_propagate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">A3</span><span class="p">)</span>
</pre></div>
<div class="code_stdout"><pre>[[0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1]]
[[ 0.043  0.021  0.992  0.982  0.051  0.991  0.982  0.014  0.025  0.988
   0.029  0.035  0.983  0.99   0.018  0.99   0.98   0.983  0.991  0.99 ]]
</pre></div><h1> Decision Boundary </h1>

<p>
Let's try to visualize the decision boundary that error final classifier learns.
</p>

<p>
The decision boundaries of both <b>Logistic Regression</b> and <b>Softmax Regression</b>
were linear. However, the decision boundary of this lecture is not linear, for obvious reasons.
Thanks to our non-linear sigmoid function. (Please see Exercise 1)
</p>
<div class="highlight"><pre><span></span><span class="n">NX</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">NY</span> <span class="o">=</span> <span class="mi">100</span>

<span class="k">def</span> <span class="nf">plot_decision_boundary_lazy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$x_2$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Decision boundary - Contour plot&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span>

  <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">NX</span><span class="p">)</span>
  <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">NY</span><span class="p">)</span>
  <span class="n">xv</span><span class="p">,</span> <span class="n">yv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
  <span class="n">X_fake</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">xv</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">yv</span><span class="o">.</span><span class="n">flatten</span><span class="p">()),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">forward_propagate</span><span class="p">(</span><span class="n">X_fake</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>

  <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">NX</span> <span class="o">*</span> <span class="n">NY</span><span class="p">)))</span> <span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">NX</span><span class="p">,</span> <span class="n">NY</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colormap</span><span class="p">[</span><span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;image.png&#39;</span><span class="p">)</span>

<span class="n">plot_decision_boundary_lazy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
</pre></div>
<img class="generated_image" width="600" src="../images/image002.png"/><p>
Here, the color of the background depicts our prediction for that imaginary point. Remember that our prediction
is one dimensional and between $[0,1]$. If it is $0.0$ it means we are classifying the point confidently as
red and if it is $1.0$ we are very confident on green.
</p>

<p>
In order to create this figure, we simply convert our one dimensional prediction into three dimensions (RGB)
using the following logic. R = prediction, G = 1 - prediction, B = 0. So, for example, if our final prediction
is, say, 0.9, then the color on that point will be $[0.9, 0.1, 0]$ which is kind of dark green.
</p>

<p>
Similarly, we can plot the same as our classifier progresses through the learning process.
As you may guess, it should start from a random point and get smarter in each step.
</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.animation</span> <span class="kn">as</span> <span class="nn">animation</span>

<span class="n">NX</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">NY</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">NX</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">NY</span><span class="p">)</span>
<span class="n">xv</span><span class="p">,</span> <span class="n">yv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
<span class="n">X_fake</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">xv</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">yv</span><span class="o">.</span><span class="n">flatten</span><span class="p">()),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_predictions</span><span class="p">(</span><span class="n">X_fake</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">forward_propagate</span><span class="p">(</span><span class="n">X_fake</span><span class="p">,</span> <span class="o">*</span><span class="n">model</span><span class="p">)</span>
  <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">NX</span> <span class="o">*</span> <span class="n">NY</span><span class="p">)))</span> <span class="p">)</span>
  <span class="k">return</span> <span class="n">predictions</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">NX</span><span class="p">,</span> <span class="n">NY</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$x_2$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Decision boundary - Animated&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
  <span class="n">im</span><span class="o">.</span><span class="n">set_array</span><span class="p">(</span><span class="n">get_predictions</span><span class="p">(</span><span class="n">X_fake</span><span class="p">,</span> <span class="n">models_cache</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">50</span><span class="p">]))</span>
  <span class="n">text_box</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;Iteration: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="mi">50</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">im</span><span class="p">,</span> <span class="n">text_box</span>

<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">get_predictions</span><span class="p">(</span><span class="n">X_fake</span><span class="p">,</span> <span class="n">models_cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="n">animated</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colormap</span><span class="p">[</span><span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">text_box</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.6</span><span class="p">,</span> <span class="s1">&#39;Iteration 0&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">16</span><span class="p">)</span>

<span class="n">anim</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">animate</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">models_cache</span><span class="p">)</span> <span class="o">/</span> <span class="mi">50</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">anim</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;animation.mp4&#39;</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="s1">&#39;avconv&#39;</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">codec</span><span class="o">=</span><span class="s2">&quot;libx264&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
</pre></div>
<video class="generated_video" width="600" controls>
<source src="../animations/animation000.mp4" type="video/mp4">
</video><p>
As you can see, it starts from a random classifier that does not seem to be working well in the
beginning. And the learning process figures out where to go next to find a better classifier.
After the learning is done, the final classifier is pretty good, in fact it has 100% accuracy.
</p>

<h1> Applying Simple Neural Network using low-level Tensorflow APIs </h1>

<p>
Here is how to train the same classifier for the above red and green points using low-level TensorFlow API.
It produces <b>exact</b> output with our own hand crafted model. Notice that it is because we start both
models from the same initial random starting point (same $W$ and same $b$).
</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="n">t_X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="bp">None</span><span class="p">])</span>
<span class="n">t_Y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">None</span><span class="p">])</span>

<span class="c1"># t_W1 = tf.Variable(tf.random_uniform((3, 2)))</span>
<span class="n">t_W1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">W1_initial</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">))</span>
<span class="n">t_b1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

<span class="c1"># t_W2 = tf.Variable(tf.random_uniform((3, 3)))</span>
<span class="n">t_W2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">W2_initial</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">))</span>
<span class="n">t_b2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

<span class="c1">#t_W3 = tf.Variable(tf.random_uniform((1, 3)))</span>
<span class="n">t_W3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">W3_initial</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">))</span>
<span class="n">t_b3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">t_Z1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">t_W1</span><span class="p">,</span> <span class="n">t_X</span><span class="p">)</span> <span class="o">+</span> <span class="n">t_b1</span>
<span class="n">t_A1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">t_Z1</span><span class="p">)</span>

<span class="n">t_Z2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">t_W2</span><span class="p">,</span> <span class="n">t_A1</span><span class="p">)</span> <span class="o">+</span> <span class="n">t_b2</span>
<span class="n">t_A2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">t_Z2</span><span class="p">)</span>

<span class="n">t_Z3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">t_W3</span><span class="p">,</span> <span class="n">t_A2</span><span class="p">)</span> <span class="o">+</span> <span class="n">t_b3</span>
<span class="n">t_A3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">t_Z3</span><span class="p">)</span>

<span class="n">t_Loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">t_Z3</span><span class="p">,</span>  <span class="n">labels</span> <span class="o">=</span> <span class="n">t_Y</span><span class="p">))</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">t_Loss</span><span class="p">)</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
   <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
   <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
      <span class="n">ttrain</span><span class="p">,</span> <span class="n">ttloss</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">train</span><span class="p">,</span> <span class="n">t_Loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">t_X</span><span class="p">:</span><span class="n">X</span><span class="p">,</span> <span class="n">t_Y</span><span class="p">:</span><span class="n">Y</span><span class="p">})</span>
      <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ttloss</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">ttloss</span> <span class="o">&lt;</span> <span class="mf">0.02</span><span class="p">:</span>
        <span class="k">break</span>

   <span class="k">print</span><span class="p">(</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">t_A3</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">t_X</span><span class="p">:</span><span class="n">X</span><span class="p">,</span> <span class="n">t_Y</span><span class="p">:</span><span class="n">Y</span><span class="p">})[</span><span class="mi">0</span><span class="p">])</span>
   <span class="k">print</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Tensorflow Loss&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of iterations&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;image.png&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
</pre></div>
<img class="generated_image" width="600" src="../images/image003.png"/>
<h1>Exercises</h1>
<ol>
  <li> We claim that the decision boundary of the 3-layer simple neural network as it explained
  in this chapter is not linear because using a non-linear activation function (sigmoid). However,
  we have used the same sigmoid function in Logistic Regression as well, and the decision boundary
  was linear. Also, softmax function doesn't look like linear at all. (Actually, what the heck is
  the defition (or the test) of a linear function?) And also (assuming sigmoid is a non-linear
  activation function) why we had a linear decision boundary on logistic regression but not the 3-layer
  simple neural network?
  </li>
</ol>

<h1>References</h1>

<ul>
  <li> http://karpathy.github.io/ </li>
  <li> http://colah.github.io/ </li>
  <li> https://github.com/tensorflow/workshops </li>
</ul>
    </div>
</div>

</body>
</html>
