<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
<head>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-51676383-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-51676383-1');
</script>

<title>Part 3: Building a Simple Neural Network</title>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
       equationNumbers: { autoNumber: "AMS" },
       TagSide: "right"

    }
  });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<link rel="stylesheet" href="pygments.css">
<link rel="stylesheet" href="style.css">
<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
</head>

<body>

<div id="outer">
    <div id="inner">
<center><h1>Part 3: Building a Simple Neural Network <span style="color: red">[Draft]</span></h1></center>
<center><b>Sait Celebi</b> (celebisait@gmail.com)</center>
<center>Last updated: September 29 2018</center><p>
"Truth is ever to be found in the simplicity, and not in the multiplicity and confusion of things."
-- Sir Isaac Newton
</p>
<a href="#introduction" class="header_style">  <h1 id="introduction">Introduction</h1>  </a>
<p>
Let's say we want to build a model to discriminate the following <b>red</b> and <b>green</b>
points in 2-dimensional space:
</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">collections</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;classic&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
              <span class="p">[</span> <span class="mf">0.00</span><span class="p">,</span><span class="o">-</span><span class="mf">0.65</span><span class="p">],</span>
	      <span class="p">[</span><span class="o">-</span><span class="mf">0.75</span><span class="p">,</span><span class="o">-</span><span class="mf">1.29</span><span class="p">],</span>
	      <span class="p">[</span> <span class="mf">1.29</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">],</span>
	      <span class="p">[</span><span class="o">-</span><span class="mf">0.46</span><span class="p">,</span><span class="o">-</span><span class="mf">0.46</span><span class="p">],</span>
	      <span class="p">[</span><span class="o">-</span><span class="mf">1.29</span><span class="p">,</span><span class="o">-</span><span class="mf">0.75</span><span class="p">],</span>
	      <span class="p">[</span> <span class="mf">0.00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">],</span>
	      <span class="p">[</span> <span class="mf">0.46</span><span class="p">,</span> <span class="mf">0.46</span><span class="p">],</span>
	      <span class="p">[</span> <span class="mf">0.46</span><span class="p">,</span><span class="o">-</span><span class="mf">0.46</span><span class="p">],</span>
	      <span class="p">[</span><span class="o">-</span><span class="mf">1.29</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">],</span>
 	      <span class="p">[</span><span class="o">-</span><span class="mf">0.46</span><span class="p">,</span> <span class="mf">0.46</span><span class="p">],</span>
	      <span class="p">[</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">],</span>
	      <span class="p">[</span> <span class="mf">0.75</span><span class="p">,</span><span class="o">-</span><span class="mf">1.29</span><span class="p">],</span>
	      <span class="p">[</span> <span class="mf">1.29</span><span class="p">,</span><span class="o">-</span><span class="mf">0.75</span><span class="p">],</span>
	      <span class="p">[</span><span class="o">-</span><span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
	      <span class="p">[</span> <span class="mf">1.50</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
	      <span class="p">[</span><span class="o">-</span><span class="mf">1.50</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
	      <span class="p">[</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.29</span><span class="p">],</span>
	      <span class="p">[</span><span class="o">-</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.29</span><span class="p">],</span>
	      <span class="p">[</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">1.50</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">colormap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">plot_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">colormap</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$x_2$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Input 2D points&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colormap</span><span class="p">[</span><span class="n">y</span><span class="p">])</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="n">plot_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">colormap</span><span class="p">,</span> <span class="s1">&#39;image.png&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
</pre></div>
<div class="executed_in">(Executed in 0.185 seconds.)</div><img class="generated_image" width="600" src="../images/image017.png"/><p>
In other words, given a point, $(x_1, x_2)$, we want to output either <b>red</b>,
or <b>green</b>. (In this tutorial 0.0 means red and 1.0 means green.)
</p>

<p>
We can build a simple Neural Network for this problem. Neural Networks are widely used
for applications ranging from face recognition, machine translation, speech to text,
self driving cars, etc.  This is a very simple neural network in terms of number of layers and
number of neurons it contains.
</p>

<p>
It's basically a Logistic Regression (or Softmax Regression) with <b>more layers</b>.
</p>
<a href="#computation_graph" class="header_style">  <h1 id="computation_graph">Computation Graph</h1>  </a><p>
Here is the visual representation of our model:
</p>

<img class="static_image" style="width: 800px;" src="../static_images/image006.png"/>

<p>
and decide if $a^{[3]} > 0.5$ for our <b>final prediction</b>.
</p>
<a href="#feed-forward_phase" class="header_style">  <h1 id="feed-forward_phase">Feed-forward Phase</h1>  </a><p>
Let's assume that we are given the weights and biases. How do we calculate the output?
</p>

<p>
We represent $\mathbf{X}$ as a matrix. $\mathbf{X}$ contains all the points.
In our case $\mathbf{X}$ contains $m=20$ samples. $\mathbf{y}$ contains all the
labels (red or green):
</p>

<p>
Here is the sizes of the matrices:
</p>

<ul>
  <li> $\mathbf{X}: 20 \times 2$ </li>
  <li> $\mathbf{y}: 20 \times 1$ </li>
  <li> $\mathbf{W}^{[1]}: 3 \times 2$ </li>
  <li> $\mathbf{b}^{[1]}: 3 \times 1$ </li>
  <li> $\mathbf{W}^{[2]}: 3 \times 3$ </li>
  <li> $\mathbf{b}^{[2]}: 3 \times 1$ </li>
  <li> $\mathbf{W}^{[3]}: 1 \times 3$ </li>
  <li> $b^{[3]}: 1 \times 1$ </li>
</ul>

<p>
Feed-forward basically means given:
$\mathbf{x}, y, \mathbf{W}^{[1]}, \mathbf{W}^{[2]}, \mathbf{W}^{[3]}$
and $\mathbf{b}^{[1]}, \mathbf{b}^{[2]}, b^{[3]}$
will produce us $a^{[3]}$. Here is step by step how we do the feed forward phase.
</p>

$$
\mathbf{z}^{[1]} = \mathbf{W}^{[1]} \mathbf{x} + \mathbf{b}^{[1]}
$$

$$
\mathbf{a}^{[1]} = g(\mathbf{z}^{[1]})
$$

$$
\mathbf{z}^{[2]} = \mathbf{W}^{[2]} \mathbf{a}^{[1]} + \mathbf{b}^{[2]}
$$

$$
\mathbf{a}^{[2]} = g(\mathbf{z}^{[2]})
$$

$$
z^{[3]} = \mathbf{W}^{[3]} \mathbf{a}^{[2]} + b^{[3]}
$$

$$
a^{[3]} = g(z^{[3]})
$$

<p>
We are using sigmoid function as the activation $g()$ function as we used before.
</p>

<p>
Let's try to apply the above equations using an <b>initial</b> random set of weights and bias.
</p>
<div class="highlight"><pre><span></span><span class="n">sigmoid</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">forward_propagate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">):</span>
  <span class="n">z1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>
  <span class="n">a1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>

  <span class="n">z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
  <span class="n">a2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>

  <span class="n">z3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W3</span><span class="p">,</span> <span class="n">a2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b3</span>
  <span class="n">a3</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z3</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">z1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">z2</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">z3</span><span class="p">,</span> <span class="n">a3</span>

<span class="n">W1_initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">W1_initial</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">W2_initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">W2_initial</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">W3_initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">W3</span> <span class="o">=</span> <span class="n">W3_initial</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">b3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">z1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">z2</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">z3</span><span class="p">,</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">forward_propagate</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">a3</span><span class="p">)</span>
</pre></div>
<div class="executed_in">(Executed in 0.003 seconds.)</div><div class="code_stdout"><pre>0
[[0.773]]
</pre></div><p>
Above we print our prediction for the first point out of 20 points.
We use random initial set of weights and bias. We are <b>randomly
initializing</b> weights and bias and feed the first $\mathbf{x}$
to our random initial model. As you can see, our prediction is pretty random
too, as expected. However, you can see that, given the weights,
and bias, it is pretty straight-forward to calculate the final prediction.
The tricky part is to <i>learn</i> those weights properly.
</p>
<a href="#cross_entropy_loss_function" class="header_style">  <h1 id="cross_entropy_loss_function">Cross Entropy Loss Function</h1>  </a><p>
In training, our goal is to <b>learn</b>: $\mathbf{W}^{[1]}, \mathbf{W}^{[2]},
\mathbf{W}^{[3]}, \mathbf{b}^{[1]}, \mathbf{b}^{[2]}, \mathbf{b}^{[3]}$
that best <b>discriminates</b> red and green points. These are called the
<b>parameters</b> of our model.
</p>

<p>
We want to find parameters that minimizes some definition of a <b>cost function</b>. We will use the same
cost function we have used before in Logistic Regression and Softmax Regression:
</p>

$$ \text{L} = - \sum_{i=1}^{M} y^{(i)} \text{log}( a^{[3](i)} ) + (1 - y^{(i)}) \text{log}( 1 - a^{[3](i)} )$$

<p>
where $a^{[3](i)}$ is the last layer's activation value corresponding to the $i$ th item in the dataset.
</p>

<p>
Please see previous lectures if you are interested understanding how we derived the cross entropy loss function.
</p>

<p>
If we add our <b>loss</b> to our computation graph:
</p>

<img class="static_image" style="width: 800px;" src="../static_images/image007.png"/>
<a href="#backpropagation" class="header_style">  <h1 id="backpropagation">Backpropagation</h1>  </a><p>
Now, we are going to have some <b>fun</b>.
</p>

<p>
Backprop is probably one of the most <b>fundamental</b> algorithms/techniques in Deep Learning.
In my opinion, mastering backprop is curicial to be able to
(1) fully understand deep learing techniques and (2) to be able to contribute new approaches in the field.
</p>

<p>
Backpropagation is simply calculating derivatives of loss w.r.t. each parameter in our model.
We need this information because we need to feed the derivatives to <b>Gradient Descent</b>.
The parameters of the model we want to compute with backprop is:
</p>


$$
\frac{d \text{L}}{d \mathbf{W}^{[i]}}, \quad \frac{d \text{L}}{d \mathbf{b}^{[i]}} \quad \forall i \in \{1,2,3\}
$$

<p>
We need to use <b>chain rule</b>, <b>iteratively</b>, to get there. The direction we apply chain rule will be
the opposite direction to the feed forward direction. In fact the name backpropagation
comes from the fact that we propagate the error (well actually the derivatives, really)
through backwards (compared to the feed-forward direction) in a step by step manner.
</p>

<p>
Here is our updated computation graph after we add the Backprop details.
</p>

<img class="static_image" style="width: 800px;" src="../static_images/image008.png"/>

<p>
Recall that we already calculated the first step of derivatives:
</p>

$$
\frac{d \text{L}}{dz^{[3]}} = a^{[3]} - y
$$

<p>
in Logistic Regression tutorial. Notice that we are using <b>exactly</b> same loss function.
(Both Logistic Regression and the model discussed in this tutorial are a binary classification task.)
</p>

<p>
Notice that this is defined <b>per sample</b>. So, we have a different $\frac{d \text{L}}{d z^{[3]}}$
value for each sample.
</p>

<p>
Let's try to go one step further and calculate $\frac{d \text{L}}{d \mathbf{W}^{[3]}}$ by keeping
in mind that we already know $\frac{d \text{L}}{dz^{[3]}}$. (This sentence mimicks why we need
<b>Chain Rule</b>)
</p>

<p>
In other words, we know how much $\text{L}$ changes if we play
with $z^{[3]}$ and we are trying to find out how much $\text{L}$ changes if we play with
$\mathbf{W}^{[3]}$.
</p>

<p>
Let's look at how we calculate $z^{[3]}$:
</p>

$$
\begin{matrix}
(\mathbf{W}^{[3]}) \\
\begin{bmatrix} 0 & 0 & 0 \end{bmatrix}
\\
\\
\mbox{}
\end{matrix}

\begin{matrix}
(\mathbf{a}^{[2]}) \\
\begin{bmatrix}
0  \\
0  \\
0  \\
\end{bmatrix}
\end{matrix}

+

\begin{matrix}
(b^{[3]})
\\
\begin{bmatrix}
0
\end{bmatrix}
\\
\\
\end{matrix}

=

\begin{matrix}
(z^{[3]})
\\
\begin{bmatrix}
0
\end{bmatrix}
\\
\\
\end{matrix}
$$

<p>
Let's look at this equation very carefully. Our simpler task for now is: "How much
$z^{[3]}$ will be affected if we play with $\mathbf{W}^{[3]}$?", i.e.,
</p>

$$
\frac{d z^{[3]}}{d \mathbf{W}^{[3]}}
$$

<p>
After finding out what the above is, we will extend it and find:
$\frac{d \text{L}}{d \mathbf{W}^{[3]}}$ using the Chain Rule.
</p>

<p>
It seems obvious <b>visually</b> that if we change, say,
$\mathbf{W}^{[3](1)}$, $z^{[3]}$ will change proportional to $\mathbf{a}^{[2](1)}$.
Notice that we are assuming that $\mathbf{a}^{[2]}$ and $b^{[3]}$ is fixed and frozen.
Using similar logic for the other items of $\mathbf{W}^{[3]}$, we can conclude:
</p>

$$
\frac{d z^{[3]}}{d \mathbf{W}^{[3]}} = \mathbf{a}^{[2]}.\text{T}
$$

<p>
Similarly, if we change $b^{[3]}$ a small amount, $z^{[3]}$ will also change as same amount
in the same direction, so:
</p>

$$
\frac{d z^{[3]}}{d b^{[3]}} = 1
$$

<p>
To finalize the calculation of $\frac{d \text{L}}{d \mathbf{W}^{[3]}}$, <b>for one sample</b>:
</p>

$$
\frac{d \text{L}}{d \mathbf{W}^{[3]}} = \frac{d \text{L}}{d z^{[3]}} \frac{d z^{[3]}}{d \mathbf{W}^{[3]}}
$$

<p>
and similarly for $\frac{d \text{L}}{d b^{[3]}}$:
</p>

$$
\frac{d \text{L}}{d b^{[3]}} = \frac{d \text{L}}{d z^{[3]}}
$$

<p>
Notice that $\frac{d \text{L}}{dz^{[3]}} \in \mathbb{R}$ and $\frac{dz^{[3]}}{d \mathbf{W}^{[3]}} \in \mathbb{R}^3$.
So, it is a scalar multiplication.
</p>

<p>
Nice.
</p>

<p>
At this moment, we calculated $\frac{d \text{L}}{d \mathbf{W}^{[3]}}$ and
$\frac{d \text{L}}{d b^{[3]}}$. Now, we want to calculate
$\frac{d \text{L}}{d \mathbf{W}^{[2]}}$ and $\frac{d \text{L}}{d \mathbf{b}^{[2]}}$.
In order to calculate them, we need $\frac{d \text{L}}{d \mathbf{a}^{[2]}}$ and
$\frac{d \text{L}}{d \mathbf{z}^{[2]}}$.
</p>

<p>
Looking to the same figure above visually, and using a similar logic, it looks obvious
<b>for one sample</b>:
</p>

$$
\frac{d z^{[3]}}{d \mathbf{a}^{[2]}} = \mathbf{W}^{[3]}.\text{T}
$$

<p>
To finalize the calculation of $\frac{d \text{L}}{d \mathbf{a}^{[2]}}$:
</p>

$$
\frac{d \text{L}}{d \mathbf{a}^{[2]}} = \frac{d \text{L}}{d z^{[3]}} \frac{d z^{[3]}}{d \mathbf{a}^{[2]}}
$$

<p>
Given $\frac{d \text{L}}{d \mathbf{a}^{[2]}}$, it is easy to get
$\frac{d \text{L}}{d \mathbf{z}^{[2]}}$. We just need to apply
the gradient of <b>sigmoid</b> function.
</p>

$$
\frac{d \text{L}}{d \mathbf{z}^{[2]}} =
  \frac{d \text{L}}{d \mathbf{a}^{[2]}} \circ \frac{d \mathbf{a}^{[2]}}{d \mathbf{z}^{[2]}} =
     \frac{d \text{L}}{d \mathbf{a}^{[2]}} \circ \left
     ( \mathbf{a}^{[2]} \circ \left ( 1 - \mathbf{a}^{[2]} \right ) \right )
$$

<p>
Now, with knowing $\frac{d \text{L}}{d \mathbf{z}^{[2]}}$, we are set to calculate
$\frac{d \text{L}}{d \mathbf{W}^{[2]}}$ and $\frac{d \text{L}}{d \mathbf{b}^{[2]}}$.
Here is how we compute $\mathbf{z}^{[2]}$:
</p>

$$
\begin{matrix}
(\mathbf{W}^{[2]}) \\
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0 \\
\end{bmatrix}
\end{matrix}

\begin{matrix}
(\mathbf{a}^{[1]}) \\
\begin{bmatrix}
0  \\
0  \\
0  \\
\end{bmatrix}
\end{matrix}

+

\begin{matrix}
(\mathbf{b}^{[2]})
\\
\begin{bmatrix}
0 \\
0 \\
0 \\
\end{bmatrix}
\end{matrix}

=

\begin{matrix}
(\mathbf{z}^{[2]})
\\
\begin{bmatrix}
0 \\
0 \\
0 \\
\end{bmatrix}
\end{matrix}
$$

<p>
It is easy to observe:
</p>

$$

\frac{d \mathbf{z}^{[2](1)}}{d \mathbf{W}^{[2]}} =
\begin{bmatrix}
  & \mathbf{a}^{[1]}.T & \\
0 & 0 & 0 \\
0 & 0 & 0 \\
\end{bmatrix},
\quad
\frac{d \mathbf{z}^{[2](2)}}{d \mathbf{W}^{[2]}} =
\begin{bmatrix}
0 & 0 & 0 \\
& \mathbf{a}^{[1]}.T & \\
0 & 0 & 0 \\
\end{bmatrix},
\quad
\frac{d \mathbf{z}^{[2](3)}}{d \mathbf{W}^{[2]}} =
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
& \mathbf{a}^{[1]}.T & \\
\end{bmatrix}

$$

<p>
Applying the chain rule, we should do something like:
</p>

$$
\frac{d \text{L}}{d \mathbf{W}^{[2]}} =
  \sum_{i=1}^{3} \frac{d \text{L}}{d \mathbf{z}^{[2](i)}}
     \frac{d \mathbf{z}^{[2](i)}}{d \mathbf{W}^{[2]}}
$$

<p>
which is a more fancy way of writing:
</p>

$$
\frac{d \text{L}}{d \mathbf{W}^{[2]}} =

\frac{d \text{L}}{d \mathbf{z}^{[2](1)}}
\begin{bmatrix}
  & \mathbf{a}^{[1]}.T & \\
0 & 0 & 0 \\
0 & 0 & 0 \\
\end{bmatrix}
+
\frac{d \text{L}}{d \mathbf{z}^{[2](2)}}
\begin{bmatrix}
0 & 0 & 0 \\
  & \mathbf{a}^{[1]}.T & \\
0 & 0 & 0 \\
\end{bmatrix}
+
\frac{d \text{L}}{d \mathbf{z}^{[2](3)}}
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
  & \mathbf{a}^{[1]}.T & \\
\end{bmatrix}
$$

<p>
which is idential to:
</p>

$$
\frac{d \text{L}}{d \mathbf{W}^{[2]}} =

\begin{bmatrix}
\\
 \frac{d \text{L}}{d \mathbf{z}^{[2]}} \\
\\
\end{bmatrix}

\begin{bmatrix}
 \mathbf{a}^{[1]}.T \\
\end{bmatrix}
$$

<p>
We are half-way there in terms of finishing the backprop.
</p>

<p>
We need to calcualte $\frac{d \text{L}}{d \mathbf{a}^{[1]}}$.
Let's look at $\frac{d \mathbf{z}^{[2]}}{d \mathbf{a}^{[1]}}$.
</p>

$$
\frac{d \text{L}}{\mathbf{a}^{[1](1)}} = \mathbf{W}^{[2](:,1)} \frac{d \text{L}}{d \mathbf{z}^{[2]}}.T, \quad
\frac{d \text{L}}{\mathbf{a}^{[1](2)}} = \mathbf{W}^{[2](:,2)} \frac{d \text{L}}{d \mathbf{z}^{[2]}}.T, \quad
\frac{d \text{L}}{\mathbf{a}^{[1](3)}} = \mathbf{W}^{[2](:,3)} \frac{d \text{L}}{d \mathbf{z}^{[2]}}.T
$$

<p>
or, equivalently:
</p>

$$
\frac{d \text{L}}{\mathbf{a}^{[1]}} = \mathbf{W}^{[2]}.T \frac{d \text{L}}{d \mathbf{z}^{[2]}}
$$

<p>
Now we only missing $\frac{d \text{L}}{d \mathbf{W}^{[1]}}$ and $\frac{d \text{L}}{db^{[1]}}$.
Let's look how we calculate $\mathbf{z}^{[1]}$:
</p>

$$
\begin{matrix}
(\mathbf{W}^{[1]}) \\
\begin{bmatrix}
0 & 0  \\
0 & 0  \\
0 & 0  \\
\end{bmatrix}
\end{matrix}

\begin{matrix}
(\mathbf{x}) \\
\begin{bmatrix}
0  \\
0  \\
\end{bmatrix}
\end{matrix}

+

\begin{matrix}
(\mathbf{b}^{[1]})
\\
\begin{bmatrix}
0 \\
0 \\
0 \\
\end{bmatrix}
\end{matrix}

=

\begin{matrix}
(\mathbf{z}^{[1]})
\\
\begin{bmatrix}
0 \\
0 \\
0 \\
\end{bmatrix}
\end{matrix}
$$

<p>
Now, let's look at:
</p>

$$
\frac{d \text{L}}{d \mathbf{W}^{[1](1,:)}} = \frac{d \text{L}}{d \mathbf{z}^{[1](1)}} \mathbf{x}.\text{T}, \quad
\frac{d \text{L}}{d \mathbf{W}^{[1](2,:)}} = \frac{d \text{L}}{d \mathbf{z}^{[1](2)}} \mathbf{x}.\text{T}, \quad
\frac{d \text{L}}{d \mathbf{W}^{[1](3,:)}} = \frac{d \text{L}}{d \mathbf{z}^{[1](3)}} \mathbf{x}.\text{T}
$$

<p>
or equivalently:
</p>

$$
\frac{d \text{L}}{d \mathbf{W}^{[1]}} = \frac{d \text{L}}{d \mathbf{z}^{[1]}} \mathbf{x}.\text{T}
$$

<p>
and as expected:
</p>

$$
\frac{d \text{L}}{d \mathbf{b}^{[1]}} = \frac{d \text{L}}{d \mathbf{z}^{[1]}}
$$

<p>
Let's apply the <b>backprop</b> altogether!
</p>
<div class="highlight"><pre><span></span><span class="n">ALPHA</span> <span class="o">=</span> <span class="mf">0.4</span> <span class="c1"># learning rate</span>

<span class="k">def</span> <span class="nf">get_loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
  <span class="k">return</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span>
               <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">a</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">get_loss_numerically_stable</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
  <span class="k">return</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span> <span class="o">+</span>
               <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">z</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))))</span>

<span class="k">def</span> <span class="nf">get_gradients_loops</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">z2</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">z3</span><span class="p">,</span> <span class="n">a3</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">):</span>
  <span class="n">dz3</span> <span class="o">=</span> <span class="n">a3</span> <span class="o">-</span> <span class="n">y</span>
  <span class="n">db3</span> <span class="o">=</span> <span class="n">dz3</span>

  <span class="n">dW3</span> <span class="o">=</span> <span class="n">dz3</span> <span class="o">*</span> <span class="n">a2</span><span class="o">.</span><span class="n">T</span>
  <span class="n">da2</span> <span class="o">=</span> <span class="n">dz3</span> <span class="o">*</span> <span class="n">W3</span><span class="o">.</span><span class="n">T</span>

  <span class="n">dz2</span> <span class="o">=</span> <span class="n">da2</span> <span class="o">*</span> <span class="p">(</span><span class="n">a2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">a2</span><span class="p">))</span>
  <span class="n">db2</span> <span class="o">=</span> <span class="n">dz2</span>

  <span class="n">dW2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">dz2</span><span class="p">,</span> <span class="n">a1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
  <span class="n">da1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dz2</span><span class="p">)</span>

  <span class="n">dz1</span> <span class="o">=</span> <span class="n">da1</span> <span class="o">*</span> <span class="p">(</span><span class="n">a1</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">a1</span><span class="p">))</span>
  <span class="n">dW1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">dz1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
  <span class="n">db1</span> <span class="o">=</span> <span class="n">dz1</span>

  <span class="k">return</span> <span class="n">dW1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dW2</span><span class="p">,</span> <span class="n">db2</span><span class="p">,</span> <span class="n">dW3</span><span class="p">,</span> <span class="n">db3</span>

<span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">dW1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dW2</span><span class="p">,</span> <span class="n">db2</span><span class="p">,</span> <span class="n">dW3</span><span class="p">,</span> <span class="n">db3</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
  <span class="n">W1</span> <span class="o">-=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="n">dW1</span>
  <span class="n">b1</span> <span class="o">-=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="n">db1</span>
  <span class="n">W2</span> <span class="o">-=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="n">dW2</span>
  <span class="n">b2</span> <span class="o">-=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="n">db2</span>
  <span class="n">W3</span> <span class="o">-=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="n">dW3</span>
  <span class="n">b3</span> <span class="o">-=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="n">db3</span>

  <span class="k">return</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span>

<span class="k">def</span> <span class="nf">get_zero_gradients</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">):</span>
  <span class="n">tdW1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">W1</span><span class="p">)</span>
  <span class="n">tdb1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">b1</span><span class="p">)</span>
  <span class="n">tdW2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">W2</span><span class="p">)</span>
  <span class="n">tdb2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span>
  <span class="n">tdW3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">W3</span><span class="p">)</span>
  <span class="n">tdb3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">b3</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tdW1</span><span class="p">,</span> <span class="n">tdb1</span><span class="p">,</span> <span class="n">tdW2</span><span class="p">,</span> <span class="n">tdb2</span><span class="p">,</span> <span class="n">tdW3</span><span class="p">,</span> <span class="n">tdb3</span>

<span class="k">def</span> <span class="nf">add_gradients</span><span class="p">(</span><span class="n">tdW1</span><span class="p">,</span> <span class="n">tdb1</span><span class="p">,</span> <span class="n">tdW2</span><span class="p">,</span> <span class="n">tdb2</span><span class="p">,</span> <span class="n">tdW3</span><span class="p">,</span> <span class="n">tdb3</span><span class="p">,</span>
                  <span class="n">dW1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dW2</span><span class="p">,</span> <span class="n">db2</span><span class="p">,</span> <span class="n">dW3</span><span class="p">,</span> <span class="n">db3</span><span class="p">):</span>
  <span class="n">tdW1</span> <span class="o">+=</span> <span class="n">dW1</span>
  <span class="n">tdb1</span> <span class="o">+=</span> <span class="n">db1</span>
  <span class="n">tdW2</span> <span class="o">+=</span> <span class="n">dW2</span>
  <span class="n">tdb2</span> <span class="o">+=</span> <span class="n">db2</span>
  <span class="n">tdW3</span> <span class="o">+=</span> <span class="n">dW3</span>
  <span class="n">tdb3</span> <span class="o">+=</span> <span class="n">db3</span>
  <span class="k">return</span> <span class="n">tdW1</span><span class="p">,</span> <span class="n">tdb1</span><span class="p">,</span> <span class="n">tdW2</span><span class="p">,</span> <span class="n">tdb2</span><span class="p">,</span> <span class="n">tdW3</span><span class="p">,</span> <span class="n">tdb3</span>

<span class="n">L_cache</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">models_cache</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">W1_initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">W1_initial</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">W2_initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">W2_initial</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">W3_initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">W3</span> <span class="o">=</span> <span class="n">W3_initial</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">b3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20000</span><span class="p">):</span>
  <span class="n">totalL</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">tdW1</span><span class="p">,</span> <span class="n">tdb1</span><span class="p">,</span> <span class="n">tdW2</span><span class="p">,</span> <span class="n">tdb2</span><span class="p">,</span> <span class="n">tdW3</span><span class="p">,</span> <span class="n">tdb3</span> <span class="o">=</span> <span class="n">get_zero_gradients</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">z1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">z2</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">z3</span><span class="p">,</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">forward_propagate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>
    <span class="n">L</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="n">get_loss_numerically_stable</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">z3</span><span class="p">)</span>
    <span class="n">totalL</span> <span class="o">+=</span> <span class="n">L</span>
    <span class="n">dW1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dW2</span><span class="p">,</span> <span class="n">db2</span><span class="p">,</span> <span class="n">dW3</span><span class="p">,</span> <span class="n">db3</span> <span class="o">=</span> <span class="n">get_gradients_loops</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">z2</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">z3</span><span class="p">,</span> <span class="n">a3</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>
    <span class="n">tdW1</span><span class="p">,</span> <span class="n">tdb1</span><span class="p">,</span> <span class="n">tdW2</span><span class="p">,</span> <span class="n">tdb2</span><span class="p">,</span> <span class="n">tdW3</span><span class="p">,</span> <span class="n">tdb3</span> <span class="o">=</span> <span class="n">add_gradients</span><span class="p">(</span><span class="n">tdW1</span><span class="p">,</span> <span class="n">tdb1</span><span class="p">,</span> <span class="n">tdW2</span><span class="p">,</span> <span class="n">tdb2</span><span class="p">,</span> <span class="n">tdW3</span><span class="p">,</span> <span class="n">tdb3</span><span class="p">,</span>
                                                        <span class="n">dW1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dW2</span><span class="p">,</span> <span class="n">db2</span><span class="p">,</span> <span class="n">dW3</span><span class="p">,</span> <span class="n">db3</span><span class="p">)</span>
  <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">tdW1</span><span class="p">,</span> <span class="n">tdb1</span><span class="p">,</span> <span class="n">tdW2</span><span class="p">,</span> <span class="n">tdb2</span><span class="p">,</span> <span class="n">tdW3</span><span class="p">,</span> <span class="n">tdb3</span><span class="p">,</span> <span class="n">ALPHA</span><span class="p">)</span>
  <span class="n">models_cache</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">W1</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">b1</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">W2</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">b2</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">W3</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">b3</span><span class="o">.</span><span class="n">copy</span><span class="p">()))</span>
  <span class="n">L_cache</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">totalL</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>

  <span class="k">if</span> <span class="n">totalL</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.005</span><span class="p">:</span>
    <span class="k">break</span>

<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of iterations&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">L_cache</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;image.png&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
</pre></div>
<div class="executed_in">(Executed in 5.724 seconds.)</div><img class="generated_image" width="600" src="../images/image018.png"/><p>
Let's see our <b>inferences</b> on the same points using our classifier.
</p>
<div class="highlight"><pre><span></span><span class="n">a3s</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">z1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">z2</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">z3</span><span class="p">,</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">forward_propagate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>
  <span class="n">a3s</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a3</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">a3s</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
<div class="executed_in">(Executed in 0.002 seconds.)</div><div class="code_stdout"><pre>(0, 0.0030237780361655293, True)
(0, 0.00495775501247672, True)
(1, 0.9966849615400128, True)
(1, 0.9963526906872795, True)
(0, 0.004312552968181347, True)
(1, 0.9957151153059337, True)
(1, 0.9954890678260839, True)
(0, 0.007462443226854086, True)
(0, 0.011330346331233178, True)
(1, 0.9944763570476098, True)
(0, 0.0030999300475868475, True)
(0, 0.006405265686412149, True)
(1, 0.9964711056673063, True)
(1, 0.995754928978925, True)
(0, 0.011433611295464191, True)
(1, 0.995643003576659, True)
(1, 0.9962928716933551, True)
(1, 0.997057154329919, True)
(1, 0.9956821191166328, True)
(1, 0.996799115067955, True)
</pre></div>If you see all "True"s above, then, we have 100% accuracy!
<a href="#decision_boundary" class="header_style">  <h1 id="decision_boundary">Decision Boundary</h1>  </a><p>
Let's try to visualize the decision boundary that error final classifier learns.
</p>

<p>
The decision boundaries of both <b>Logistic Regression</b> and <b>Softmax Regression</b>
were linear. However, the decision boundary of this lecture is not linear, for obvious reasons.
Thanks to our non-linear sigmoid function. (Please see Exercise 1)
</p>
<div class="highlight"><pre><span></span><span class="n">NX</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">NY</span> <span class="o">=</span> <span class="mi">40</span>

<span class="k">def</span> <span class="nf">plot_decision_boundary_lazy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$x_2$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Decision boundary - Contour plot&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span>

  <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">NX</span><span class="p">)</span>
  <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">NY</span><span class="p">)</span>

  <span class="n">xv</span><span class="p">,</span> <span class="n">yv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

  <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">xv</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">yv</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">z1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">z2</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">z3</span><span class="p">,</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">forward_propagate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>
    <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a3</span><span class="p">)</span>

  <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">NX</span> <span class="o">*</span> <span class="n">NY</span><span class="p">)</span>
  <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">NX</span> <span class="o">*</span> <span class="n">NY</span><span class="p">)))</span> <span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">NX</span><span class="p">,</span> <span class="n">NY</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colormap</span><span class="p">[</span><span class="n">y</span><span class="p">])</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;image.png&#39;</span><span class="p">)</span>

<span class="n">plot_decision_boundary_lazy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
</pre></div>
<div class="executed_in">(Executed in 0.209 seconds.)</div><img class="generated_image" width="600" src="../images/image019.png"/><p>
Here, the color of the background depicts our prediction for that imaginary point. Remember that our prediction
is one dimensional and between $[0,1]$. If it is $0.0$ it means we are classifying the point confidently as
red and if it is $1.0$ we are very confident on green.
</p>

<p>
In order to create this figure, we simply convert our one dimensional prediction into three dimensions (RGB)
using the following logic. R = prediction, G = 1 - prediction, B = 0. So, for example, if our final prediction
is, say, 0.9, then the color on that point will be $[0.9, 0.1, 0]$ which is kind of dark green.
</p>

<p>
Similarly, we can plot the same as our classifier progresses through the learning process.
As you may guess, it should start from a random point and get smarter in each step.
</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.animation</span> <span class="kn">as</span> <span class="nn">animation</span>

<span class="n">NX</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">NY</span> <span class="o">=</span> <span class="mi">40</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">NX</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">NY</span><span class="p">)</span>
<span class="n">xv</span><span class="p">,</span> <span class="n">yv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_predictions</span><span class="p">(</span><span class="n">xv</span><span class="p">,</span> <span class="n">yv</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
  <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">xv</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">yv</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">z1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">z2</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">z3</span><span class="p">,</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">forward_propagate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">model</span><span class="p">)</span>
    <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a3</span><span class="p">)</span>

  <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">NX</span> <span class="o">*</span> <span class="n">NY</span><span class="p">)</span>
  <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">NX</span> <span class="o">*</span> <span class="n">NY</span><span class="p">)))</span> <span class="p">)</span>
  <span class="k">return</span> <span class="n">predictions</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">NX</span><span class="p">,</span> <span class="n">NY</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$x_2$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Decision boundary - Animated&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
  <span class="n">im</span><span class="o">.</span><span class="n">set_array</span><span class="p">(</span><span class="n">get_predictions</span><span class="p">(</span><span class="n">xv</span><span class="p">,</span> <span class="n">yv</span><span class="p">,</span> <span class="n">models_cache</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">50</span><span class="p">]))</span>
  <span class="n">text_box</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;Iteration: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="mi">50</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">im</span><span class="p">,</span> <span class="n">text_box</span>

<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">get_predictions</span><span class="p">(</span><span class="n">xv</span><span class="p">,</span> <span class="n">yv</span><span class="p">,</span> <span class="n">models_cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
               <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="n">animated</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colormap</span><span class="p">[</span><span class="n">y</span><span class="p">])</span>
<span class="n">text_box</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.6</span><span class="p">,</span> <span class="s1">&#39;Iteration 0&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">16</span><span class="p">)</span>

<span class="n">anim</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">animate</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">models_cache</span><span class="p">)</span> <span class="o">/</span> <span class="mi">50</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">anim</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;animation.mp4&#39;</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="s1">&#39;avconv&#39;</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">codec</span><span class="o">=</span><span class="s2">&quot;libx264&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
</pre></div>
<div class="executed_in">(Executed in 7.301 seconds.)</div><video class="generated_video" width="600" controls>
<source src="../animations/animation006.mp4" type="video/mp4">
</video><p>
As you can see, it starts from a random classifier that does not seem to be working well in the
beginning. And the learning process figures out where to go next to find a better classifier.
After the learning is done, the final classifier is pretty good, in fact it has 100% accuracy.
</p>
<a href="#applying_simple_neural_network_using_low-level_tensorflow_apis" class="header_style">  <h1 id="applying_simple_neural_network_using_low-level_tensorflow_apis">Applying Simple Neural Network using low-level Tensorflow APIs</h1>  </a><p>
Here is how to train the same classifier for the above red and green points using low-level TensorFlow API.
It produces <b>exact</b> same output with our own hand crafted model. Notice that it is because we start both
models from the same initial random starting point (same $W$ and same $b$) using the same <b>learning rate</b>.
</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="n">t_X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="bp">None</span><span class="p">])</span>
<span class="n">t_Y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">None</span><span class="p">])</span>

<span class="c1"># t_W1 = tf.Variable(tf.random_uniform((3, 2)))</span>
<span class="n">t_W1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">W1_initial</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">))</span>
<span class="n">t_b1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

<span class="c1"># t_W2 = tf.Variable(tf.random_uniform((3, 3)))</span>
<span class="n">t_W2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">W2_initial</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">))</span>
<span class="n">t_b2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

<span class="c1">#t_W3 = tf.Variable(tf.random_uniform((1, 3)))</span>
<span class="n">t_W3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">W3_initial</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">))</span>
<span class="n">t_b3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">t_Z1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">t_W1</span><span class="p">,</span> <span class="n">t_X</span><span class="p">)</span> <span class="o">+</span> <span class="n">t_b1</span>
<span class="n">t_A1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">t_Z1</span><span class="p">)</span>

<span class="n">t_Z2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">t_W2</span><span class="p">,</span> <span class="n">t_A1</span><span class="p">)</span> <span class="o">+</span> <span class="n">t_b2</span>
<span class="n">t_A2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">t_Z2</span><span class="p">)</span>

<span class="n">t_Z3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">t_W3</span><span class="p">,</span> <span class="n">t_A2</span><span class="p">)</span> <span class="o">+</span> <span class="n">t_b3</span>
<span class="n">t_A3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">t_Z3</span><span class="p">)</span>

<span class="n">t_Loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">t_Z3</span><span class="p">,</span>  <span class="n">labels</span> <span class="o">=</span> <span class="n">t_Y</span><span class="p">))</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">ALPHA</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">t_Loss</span><span class="p">)</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
  <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
  <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20000</span><span class="p">):</span>
    <span class="n">ttrain</span><span class="p">,</span> <span class="n">ttloss</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">train</span><span class="p">,</span> <span class="n">t_Loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">t_X</span><span class="p">:</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">t_Y</span><span class="p">:</span><span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">)})</span>
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ttloss</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">ttloss</span> <span class="o">&lt;</span> <span class="mf">0.005</span><span class="p">:</span>
      <span class="k">break</span>

<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Tensorflow Loss&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of iterations&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;image.png&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
</pre></div>
<div class="executed_in">(Executed in 2.196 seconds.)</div><img class="generated_image" width="600" src="../images/image020.png"/><a href="#exercises" class="header_style">  <h1 id="exercises">Exercises</h1>  </a><ol>
  <li> We claim that the decision boundary of the 3-layer simple neural network as it explained
  in this chapter is not linear because using a non-linear activation function (sigmoid). However,
  we have used the same sigmoid function in Logistic Regression as well, and the decision boundary
  was linear. Also, softmax function doesn't look like linear at all. (Actually, what the heck is
  the defition (or the test) of a linear function?) And also (assuming sigmoid is a non-linear
  activation function) why we had a linear decision boundary on logistic regression but not the 3-layer
  simple neural network?
  </li>
</ol>
<a href="#references" class="header_style">  <h1 id="references">References</h1>  </a><ul>
  <li> http://karpathy.github.io/ </li>
  <li> http://colah.github.io/ </li>
  <li> https://github.com/tensorflow/workshops </li>
</ul>
    </div>
</div>

</body>
</html>
